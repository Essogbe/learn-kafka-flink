

<img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTun0EB8a4MYo8nUcsgWU2IBfSxjXPmODj44lGKzx9Pcw&s" width="800" height="400">

# GLOSSAIRE KAFKA FLINK
### DÃ©couvrons ensemble quelques termes et concepts ğŸ“š liÃ©s aux architectures Kafka et Flink.  

### KAFKA
#### Pub-Sub Pattern :
Un modÃ¨le de messagerie est simplement un moyen par lequel les messages (un mot sophistiquÃ© pour des bits de donnÃ©es) sont transmis entre un expÃ©diteur et un destinataire. Il existe plusieurs modÃ¨les de messagerie (par exemple, diffusion ou demande-rÃ©ponse), mais nous nous concentrerons sur le modÃ¨le de messagerie **Publish-Subscribe** pour nos besoins. Avec la messagerie **Publish-Subscribe** , les expÃ©diteurs (Ã©galement appelÃ©s **Publisher**) envoient des messages Ã  plusieurs consommateurs (Ã©galement appelÃ©s **Subscriber**) en utilisant une seule destination. Cette destination est souvent connue sous le nom de **topic** ğŸ“¬

#### Event :
Un Ã©vÃ©nement enregistre le fait que Â« quelque chose s'est produit Â» dans le monde ou dans votre entreprise. On l'appelle Ã©galement enregistrement ou message . Lorsque vous lisez ou Ã©crivez des donnÃ©es dans Kafka, vous le faites sous forme d'Ã©vÃ©nements. Conceptuellement, un Ã©vÃ©nement possÃ¨de une clÃ©, une valeur, un horodatage et des en-tÃªtes de mÃ©tadonnÃ©es facultatifs. Voici un exemple d'Ã©vÃ©nementÂ :

 - ClÃ© d'Ã©vÃ©nementÂ : "Alice"
 - Valeur de l'Ã©vÃ©nementÂ :Â Â«Â A effectuÃ© un paiement de 200Â $ Ã  BobÂ Â»
 - Horodatage de l'Ã©vÃ©nementÂ : "25Â juinÂ 2020 Ã  14h06" ğŸ•°ï¸

#### Producer :
Ce sont ces applications client qui publient (Ã©crivent) des Ã©vÃ©nements sur Kafka ğŸ“¤

#### Consumer :
Ce sont ces applications client qui s'abonnent (lisent et traitent ) des Ã©vÃ©nements sur Kafka ğŸ“¥

#### Topic :

Les Ã©vÃ©nements sont organisÃ©s et stockÃ©s durablement dans des topics (rubriques en franÃ§ais). TrÃ¨s simplifiÃ©, un topic est similaire Ã  un dossier dans un systÃ¨me de fichiers et les Ã©vÃ©nements sont les fichiers de ce dossier. Un exemple de nom de sujet pourrait Ãªtre Â«Â paiementsÂ Â». Les topics dans Kafka sont toujours multi-producteurs et multi-abonnÃ©sÂ : un topic peut avoir zÃ©ro, un ou plusieurs *producers* qui y Ã©crivent des Ã©vÃ©nements, ainsi que zÃ©ro, un ou plusieurs *consumers* qui s'abonnent Ã  ces Ã©vÃ©nements . Un topic dans Kafka est une catÃ©gorie ou un nom de flux dÃ©fini par l'utilisateur dans lequel les donnÃ©es sont stockÃ©es et publiÃ©es. En dâ€™autres termes, un topic est simplement un log dâ€™Ã©vÃ©nements. Dans un cas d'utilisation du suivi de l'activitÃ© d'un site Web, par exemple, il peut y avoir un sujet portant le nom de Â« clic Â» qui reÃ§oit et stocke un Ã©vÃ©nement Â« clic Â» chaque fois qu'un utilisateur clique sur un certain bouton. ğŸ““

#### Partition:

Les topics dans Kafka sont partitionnÃ©s, c'est-Ã -dire que nous divisons un sujet en plusieurs fichiers journaux pouvant rÃ©sider sur des brokers Kafka distincts. Cette Ã©volutivitÃ© est importante non seulement parce qu'elle permet aux applications clientes de publier/s'abonner simultanÃ©ment Ã  de nombreux courtiers, mais Ã©galement parce qu'elle garantit une haute disponibilitÃ© des donnÃ©es puisque les partitions sont rÃ©pliquÃ©es sur plusieurs brokers. Si un broker Kafka de votre cluster tombe en panne, par exemple, Kafka peut basculer en toute sÃ©curitÃ© vers les rÃ©plicas de partition sur les autres brokers. ğŸ“¦

Enfin, nous devons parler de la faÃ§on dont les Ã©vÃ©nements sont ordonnÃ©s dans les partitions. Pour comprendre cela, revenons Ã  notre cas dâ€™utilisation de lâ€™activitÃ© de trafic sur le site Web. Supposons que nous divisons notre sujet Â« clic Â» en trois partitions.

Chaque fois que notre client Web publie un Ã©vÃ©nement Â« clic Â» sur notre sujet, cet Ã©vÃ©nement sera ajoutÃ© Ã  l'une de nos trois partitions. Si une clÃ© est incluse avec la charge utile de l'Ã©vÃ©nement, elle sera utilisÃ©e pour dÃ©terminer l'affectation des partitions, sinon les Ã©vÃ©nements sont envoyÃ©s aux partitions de maniÃ¨re circulaire. Les Ã©vÃ©nements sont ajoutÃ©s et stockÃ©s dans les partitions de maniÃ¨re sÃ©quentielle, et l'ID individuel obtenu par chaque Ã©vÃ©nement (par exemple, 0 pour le premier Ã©vÃ©nement, 1 pour le second, et ainsi de suite) est appelÃ© un **offset** . ğŸ”¢



![alt text](https://github.com/Essogbe/learn-kafka-flink/blob/main/kafka-partition.png?raw=true)

ğŸ“Š

#### Replications :

Pour rendre vos donnÃ©es tolÃ©rantes aux pannes et hautement disponibles, chaque topic peut Ãªtre rÃ©pliquÃ©, mÃªme dans plusieurs rÃ©gions gÃ©ographiques ou data center, de sorte qu'il y ait toujours plusieurs brokers qui disposent d'une copie des donnÃ©es au cas oÃ¹ les choses tournent mal, vous souhaitez faire la maintenance des brokers, et ainsi de suite. Un paramÃ¨tre de production courant est un facteur de rÃ©plication de 3, c'est-Ã -dire qu'il y aura toujours trois copies de vos donnÃ©es. Cette rÃ©plication est effectuÃ©e au niveau des partitions thÃ©matiques. ğŸ”„

#### Leader-Follower

Pour Ã©viter la confusion inÃ©vitable liÃ©e Ã  la prÃ©sence Ã  la fois des donnÃ©es rÃ©elles et de leurs copies dans un cluster (par exemple, comment un producteur saura-t-il vers quel broker publier les donnÃ©es pour une partition particuliÃ¨re ?), Kafka suit un systÃ¨me **leader-follower**. De cette faÃ§on, un broker peut Ãªtre dÃ©fini comme leader d'une partition de topic et le reste des brokers comme followers de cette partition, seul le leader Ã©tant capable de gÃ©rer ces demandes des clients. ğŸ©

#### Broker :

Un cluster Kafka est composÃ© d'un ou plusieurs serveurs appelÃ©s brokers ou brokers  Kafka. Un broker est un conteneur contenant plusieurs sujets avec leurs multiples partitions. Les brokers du cluster sont identifiÃ©s uniquement par un identifiant entier. Les brokers Kafka sont Ã©galement appelÃ©s brokers Bootstrap, car la connexion avec un courtier signifie une connexion avec l'ensemble du cluster. Bien qu'un courtier ne contienne pas des donnÃ©es entiÃ¨res, chaque courtier du cluster connaÃ®t tous les autres brokers, partitions ainsi que topics. ğŸ“¡

### FLINK


#### Streaming Data Processing ğŸŒŠ

Apache Flink est un framework de traitement de donnÃ©es distribuÃ© et open source, conÃ§u pour traiter efficacement les flux de donnÃ©es en temps rÃ©el et les ensembles de donnÃ©es batch. Il offre un modÃ¨le de programmation unifiÃ© pour les deux types de traitement, ce qui permet aux dÃ©veloppeurs de construire des applications de traitement de donnÃ©es complexes avec simplicitÃ©.

#### DataStream API ğŸ“¦

La DataStream API est l'une des principales API offertes par Apache Flink pour le traitement de flux de donnÃ©es en temps rÃ©el. Elle permet aux dÃ©veloppeurs de dÃ©finir des pipelines de traitement de donnÃ©es en spÃ©cifiant des opÃ©rations de transformation sur des flux de donnÃ©es. Les opÃ©rations peuvent inclure le filtrage, le mapping, l'agrÃ©gation, etc.

#### DataSet API ğŸ“Š

En plus de la DataStream API, Apache Flink propose Ã©galement la DataSet API pour le traitement de donnÃ©es batch. Cette API permet de manipuler des ensembles de donnÃ©es statiques et offre des opÃ©rations de transformation similaires Ã  celles de la DataStream API. Cela permet aux dÃ©veloppeurs de crÃ©er des pipelines de traitement de donnÃ©es cohÃ©rents pour les donnÃ©es batch et les donnÃ©es en continu.

#### Transformation Functions ğŸ”„

Les fonctions de transformation sont des fonctions dÃ©finies par l'utilisateur qui spÃ©cifient le comportement des opÃ©rations de transformation sur les flux de donnÃ©es. Elles sont utilisÃ©es pour effectuer des manipulations sur les donnÃ©es telles que le filtrage, le mapping, l'agrÃ©gation, etc. Les fonctions de transformation peuvent Ãªtre simples (comme un map ou un filter) ou complexes (comme une fenÃªtre temporelle ou un join).

#### Stateful Processing ğŸ§ 

Apache Flink prend en charge le traitement avec Ã©tat, ce qui signifie qu'il peut maintenir et gÃ©rer l'Ã©tat des donnÃ©es tout au long du traitement. Cela permet aux dÃ©veloppeurs de crÃ©er des applications qui peuvent maintenir un contexte ou une mÃ©moire tout en traitant les flux de donnÃ©es. Le traitement avec Ã©tat est essentiel pour de nombreux cas d'utilisation, tels que le calcul d'agrÃ©gats, les fenÃªtres temporelles et les jointures de flux.

#### Fault Tolerance ğŸ›¡ï¸

La tolÃ©rance aux pannes est une caractÃ©ristique essentielle d'Apache Flink. Il garantit que les donnÃ©es sont traitÃ©es de maniÃ¨re fiable mÃªme en cas de dÃ©faillance matÃ©rielle ou logicielle. Flink utilise des mÃ©canismes de sauvegarde et de rÃ©cupÃ©ration pour garantir que les donnÃ©es sont traitÃ©es exactement une fois, mÃªme en cas de dÃ©faillance du systÃ¨me.

#### Flink JobManager ğŸ© et TaskManager ğŸ“¡

Dans un cluster Apache Flink, il y a deux types de nÅ“uds principaux : JobManager et TaskManager. Le JobManager coordonne les tÃ¢ches et la planification des travaux, tandis que le TaskManager exÃ©cute rÃ©ellement les tÃ¢ches de traitement des donnÃ©es. Ensemble, ces deux composants permettent Ã  Flink de distribuer efficacement le traitement des donnÃ©es sur un cluster de machines.

#### Streaming Sources and Sinks ğŸš°

Les sources et les puits de streaming sont des composants qui permettent Ã  Apache Flink de lire des donnÃ©es Ã  partir de diffÃ©rentes sources externes (comme Kafka, HDFS, ou des sockets) et d'Ã©crire des rÃ©sultats de traitement vers diffÃ©rentes destinations (comme Kafka, HDFS, ou des bases de donnÃ©es). Ils fournissent une interface pour connecter facilement Flink Ã  d'autres systÃ¨mes et applications.

